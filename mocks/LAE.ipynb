{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e507f41-627e-4a89-8193-3772efcfbf06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2f7dd9-95c4-4972-bdef-a3547ecb951b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# Import the Class class.\n",
    "from classy import Class\n",
    "# Import velocileptors.\n",
    "from velocileptors.LPT.lpt_rsd_fftw import LPT_RSD\n",
    "# Gamma function for wp(R).\n",
    "from scipy.special import gamma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f9c07d-53a9-47eb-a759-7612d43df34b",
   "metadata": {},
   "source": [
    "## LAE clustering\n",
    "\n",
    "Let's look at the clustering of LAEs in the mocks, using pre-generated data files created by AbacusHOD and theoretical predictions from Velocileptors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90454f77-36ba-4578-8829-cc4136a86cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "lae = json.load(open(\"lae_clustering_c000_ph100_s.json\",\"r\"))\n",
    "Lbox= lae['BoxSize']\n",
    "#\n",
    "print(\"# OmM={:.3f}, H0={:.2f}, z={:.2f}\".format(lae['Omega_M'],lae['H0'],lae['Redshift']))\n",
    "print(\"# Simulation box of side length {:.0f}Mpc/h.\".format(Lbox))\n",
    "print(\"# {:33s} {:>6s} {:>10s}\".format('HOD params','fsat','nbar'))\n",
    "for samp in lae['mocks']:\n",
    "    hodstr = \"\"\n",
    "    for p in samp['hod']: hodstr += \" {:6.2f}\".format(p)\n",
    "    print(hodstr+\" {:6.2f} {:10.2e}\".format(samp['fsat'],samp['nobj']/Lbox**3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3cc9284-9378-457c-9ee8-6c6c760bda9e",
   "metadata": {},
   "source": [
    "### Linear theory\n",
    "\n",
    "First set up the linear theory and background quantities for this cosmology using CLASS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac26174-2a80-4ac6-82c5-d31dd1f828cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the class instance.\n",
    "params = {\n",
    "    'output': 'tCl lCl mPk',\n",
    "    'l_max_scalars': 2000,\n",
    "    'P_k_max_h/Mpc': 50.,\n",
    "    'z_pk': '0.0,10',\n",
    "    'lensing': 'yes',\n",
    "    'A_s': np.exp(3.040)*1e-10,\n",
    "    'n_s': 0.96824,\n",
    "    'h': 0.6770,\n",
    "    'N_ur': 2.0328,\n",
    "    'N_ncdm': 1,\n",
    "    'tau_reio': 0.0568,\n",
    "    'omega_b': 0.022447,\n",
    "    'omega_cdm': 0.11923}\n",
    "# Now update some keys with N-body values.\n",
    "for k in ['n_s','omega_b','omega_cdm',\\\n",
    "          'omega_ncdm','N_ncdm','N_ur']:\n",
    "    params[k] = lae[k]\n",
    "params['h'] = lae['H0']/100.0\n",
    "#\n",
    "cosmo = Class()\n",
    "cosmo.set(params)\n",
    "cosmo.compute()\n",
    "#\n",
    "wb = cosmo.omega_b()\n",
    "wnu= params['omega_ncdm'] # wnu= 0.0106 * params['m_ncdm']\n",
    "#\n",
    "print(\"OmegaM=\",cosmo.Omega_m())\n",
    "print(\"sigma8=\",cosmo.sigma8())\n",
    "print(\"hubble=\",cosmo.h())\n",
    "print(\"omegab=\",wb)\n",
    "print(\"omegav=\",wnu)\n",
    "#\n",
    "cosmo.get_current_derived_parameters(['H0','Omega_Lambda',\\\n",
    "                                      'age','conformal_age','Neff',\\\n",
    "                                      'z_reio','100*theta_s','rs_rec','rs_d'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2740f2-2917-43a4-8517-a083ce9cc9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "zz = lae['Redshift']\n",
    "ff = cosmo.scale_independent_growth_factor_f(zz)\n",
    "print(\"z={:.2f}, f={:.4f}\".format(zz,ff))\n",
    "#\n",
    "hub= cosmo.h()                # To convert to \"conventional\" Mpc/h units.\n",
    "kk = np.logspace(-4.0,1.5,1000)\n",
    "pk = np.array( [cosmo.pk(k*hub,zz)*hub**3 for k in kk] )\n",
    "pl = np.array( [cosmo.pk_lin(k*hub,zz)*hub**3 for k in kk] )\n",
    "#\n",
    "# Compute the Zeldovich displacement and hence k_{nl}.\n",
    "knl= 1/np.sqrt( np.trapz(pl,x=kk)/6./np.pi**2 )\n",
    "print(\"knl=\",knl,\" h/Mpc.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46338cee-889c-4f1e-97c0-8434ebd2542b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,1,figsize=(6,4.5))\n",
    "ax.plot(kk,pk,label=\"$z={:.1f}$\".format(zz))\n",
    "ax.legend()\n",
    "ax.set_xscale('log')\n",
    "ax.set_yscale('log')\n",
    "ax.set_xlabel(r'$k\\quad [h\\,{\\rm Mpc}^{-1}]$',fontsize=18)\n",
    "ax.set_ylabel(r'$P(k)\\quad [h^{-3}{\\rm Mpc}^3]$',fontsize=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab13a01-e08a-469b-b1a0-da93a06adc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xi_mm(rr,zz):\n",
    "    \"\"\"Brute force xi_mm(r) for scalar r in Mpc/h.\"\"\"\n",
    "    kv = np.linspace(1e-3,50/rr,2500)\n",
    "    ap = np.cos(np.pi/2*kv/kv[-1]) # Apodize the integral.\n",
    "    j0 = np.sin(kv*rr)/(kv*rr)\n",
    "    pv = np.array( [cosmo.pk(k*hub,zz)*hub**3 for k in kv] )\n",
    "    xi = np.trapz(kv**2*pv/(2*np.pi**2) * j0 * ap,x=kv)\n",
    "    return(xi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabb693f-cf3a-48c5-b344-b4f7b8285964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's just look at \"xi(r)\" for the matter spectrum,\n",
    "# using linear theory just to get a feel for sizes.\n",
    "for rr in [1.0,2.0]:\n",
    "    print(\"xi({:5.2f})={:5.2f}\".format(rr,xi_mm(rr,zz))) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baab137b-6b79-45a9-9bf1-1d2a3294461a",
   "metadata": {},
   "source": [
    "### LAE data\n",
    "\n",
    "Get some routines to help massage LAE data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a2fb2f-429a-4823-bf58-002c9f78e5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schechter function fits from the literature.  The phi* definition\n",
    "# is in terms of L, i.e. we need a ln(10) going to lgL [erg/s].\n",
    "# phi* is in units of Mpc^{-3} and converted to Mpc/h below.\n",
    "LFlist = []\n",
    "LFlist.append({'zfid':2.2,'phis':3.37e-4,'Lstar':4.87e42,'alpha':-1.80,\\\n",
    "               'ref':'Konno+16'})\n",
    "LFlist.append({'zfid':3.1,'phis':3.90e-4,'Lstar':8.49e42,'alpha':-1.80,\\\n",
    "               'ref':'Konno+16'})\n",
    "LFlist.append({'zfid':3.7,'phis':3.31e-4,'Lstar':9.16e42,'alpha':-1.80,\\\n",
    "               'ref':'Konno+16'})\n",
    "#LFlist.append({'zfid':3.7,'phis':3.4e-4,'Lstar':1.02e43,'alpha':-1.50,\\\n",
    "#               'ref':'Ouchi+08'})\n",
    "LFlist.append({'zfid':5.7,'phis':4.44e-4,'Lstar':9.09e42,'alpha':-1.80,\\\n",
    "               'ref':'Konno+16'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26f38d9-e7c6-41e8-93a0-1dd2094547e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nbar_fit(lgL,zz):\n",
    "    \"\"\"Computes nbar, in [Mpc/h]^{-3}, given line luminosity lgL [erg/s]\n",
    "    for LAEs.\"\"\"\n",
    "    # Choose the closest redshift in the table.\n",
    "    delz= np.array([np.abs(zz-lf['zfid']) for lf in LFlist])\n",
    "    lf  = LFlist[np.argmin(delz)]\n",
    "    # Get the Schechter paramerers, converting to Mpc/h units.\n",
    "    hub = cosmo.h()\n",
    "    phis,lgLstar,alpha = lf['phis']/hub**3,np.log10(lf['Lstar']),lf['alpha']\n",
    "    # Just brute-force the Schechter integral, it's plenty fast enough.\n",
    "    logl = np.linspace(lgL,lgLstar+10,1000)\n",
    "    ll   = 10.0**(logl-lgLstar)\n",
    "    lf   = np.log(10)*phis * ll**(alpha+1) * np.exp(-ll)\n",
    "    nbar = np.trapz(lf,logl)\n",
    "    return(nbar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e09686-1b08-4fa4-89b3-756946f66dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flux2L(zz):\n",
    "    \"\"\"Convert a flux in erg/s/cm2 to log10(L) in [erg/s].\n",
    "    Add the returned value to log10(flux) to get log10(L).\"\"\"\n",
    "    Mpc_cm = 3.086e24 # 1 Mpc in cm.\n",
    "    dL     = cosmo.luminosity_distance(zz)\n",
    "    val    = np.log10(4*np.pi)+2*(np.log10(dL)+np.log10(Mpc_cm))\n",
    "    return(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828eea81-38b9-48ff-820e-cca4aa6fc14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some helpful numbers.\n",
    "flux = 5e-17\n",
    "lgL  = np.log10(flux) + flux2L(zz)\n",
    "chi  = cosmo.comoving_distance(zz) * cosmo.h()\n",
    "#\n",
    "print(\"z    ={:5.1f}\".format(zz))\n",
    "print(\"Flux ={:10.2e} [erg/s/cm^2]\".format(flux))\n",
    "print(\"lgL  ={:6.2f} [erg/s]\".format(lgL))\n",
    "print(\"nbar ={:10.2e}\".format(nbar_fit(lgL,zz))+r' [Mpc/h]^3')\n",
    "print(\"chi  ={:5.0f}Mpc/h\".format(chi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f5fa10-80ce-4131-bd60-382d82fd326a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How much would we need to downsample each HOD model to\n",
    "# match the nbar for this flux limit?\n",
    "ntar = nbar_fit(lgL,zz) * Lbox**3\n",
    "print(\"# {:>4s} {:>10s}\".format('lgMc','frac'))\n",
    "for samp in lae['mocks']:\n",
    "    print(\"{:6.2f} {:10.2e}\".format(samp['hod'][0],ntar/samp['nobj']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529b2386-f1ed-41eb-8fee-aa1915d4cead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table 2 of Khostovan+19: https://arxiv.org/pdf/1811.00556.pdf\n",
    "# IA484: z=2.99 \\pm 0.09\n",
    "gam,r0,dr0 = 1.80,3.85,0.45 # Mpc/h.\n",
    "# Compute wp(R) as:\n",
    "R   = np.logspace(-1,1,25)\n",
    "wpR = R**(1-gam) * r0**gam * np.sqrt(np.pi)*gamma(gam/2-0.5)/gamma(gam/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa38034c-db97-4eff-bc77-a5296098670d",
   "metadata": {},
   "source": [
    "### Velocileptors\n",
    "\n",
    "Set up the velocileptors instance and just compute an example with semi-randomly chosen parameters to exercise the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37559d58-65a3-4d93-9f8b-5cea604780f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lpt = LPT_RSD(kk,pl,kIR=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c529fe47-3f02-4796-aaf9-16fa61c33b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# b1,b2,bs, b3: linear, quadratic & cubic bias parameters\n",
    "# alpha0,alpha2,alpha4,alpha6: counterterms\n",
    "# sn0,sn2,sn4: stochastic contributions to P(k) and sigma^2.\n",
    "biases = [1.55,-0.5,0.1,0.0]\n",
    "cterms = [-1.0,-2.0,0.0,0.0]\n",
    "stoch  = [0, 0, 0]\n",
    "pars   = biases + cterms + stoch\n",
    "#\n",
    "#\n",
    "lpt.make_pltable(ff,apar=1,aperp=1,kmin=5e-3,kmax=1.0,nk=100,nmax=4)\n",
    "xi0,xi2,xi4 = lpt.combine_bias_terms_xiell(pars)\n",
    "#\n",
    "fig,ax = plt.subplots(1,1,figsize=(6,4.5))\n",
    "ax.plot(xi0[0], xi0[0]**2*xi0[1],label=r'$\\ell = 0$')\n",
    "ax.plot(xi2[0],-xi2[0]**2*xi2[1],label=r'$\\ell = 2$')\n",
    "ax.plot(xi4[0], xi4[0]**2*xi4[1],label=r'$\\ell = 4$')\n",
    "ax.legend(title='$z={:.1f}$'.format(zz))\n",
    "ax.set_xlim(0.0,150.0)\n",
    "ax.set_ylim(-10.,35.0)\n",
    "ax.set_xscale('linear')\n",
    "ax.set_yscale('linear')\n",
    "ax.set_xlabel(r'$s\\quad [h^{-1}\\,{\\rm Mpc}]$',fontsize=18)\n",
    "ax.set_ylabel(r'$i^\\ell\\ s^2\\xi_\\ell(s)\\quad [h^{-2}{\\rm Mpc}^2]$',fontsize=18)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5ccfcf-0ba7-4127-afb0-53d8396c0e92",
   "metadata": {},
   "source": [
    "### Fit to N-body\n",
    "\n",
    "Now we can try to fit to our N-body results.  For now we ignore variance reduction or other tricks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db195ba9-a80b-4862-a101-596fce875cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Begin by looking at the wp(R) results, i.e. without\n",
    "# redshift-space distortions.\n",
    "fig,ax = plt.subplots(1,1,figsize=(6,4.5))\n",
    "# First plot the N-body wp(R).\n",
    "R,icol = np.array(lae['R']),0\n",
    "for samp in lae['mocks']:\n",
    "    ax.plot(R,samp['wp'],'s',color='C'+str(icol),\\\n",
    "            mfc='None',label=\"{:5.2f}\".format(samp['hod'][0]))\n",
    "    icol = (icol+1)%10\n",
    "# Now plot a power-law fit to the data.  This fit is\n",
    "# suspect because it was done in the data neglecting\n",
    "# redshift-space distortions.\n",
    "R   = np.logspace(0,1,25)\n",
    "wpR = R**(1-gam) * r0**gam * np.sqrt(np.pi)*gamma(gam/2-0.5)/gamma(gam/2)\n",
    "wpup= R**(1-gam) * (r0+dr0)**gam * np.sqrt(np.pi)*gamma(gam/2-0.5)/gamma(gam/2)\n",
    "wpdn= R**(1-gam) * (r0-dr0)**gam * np.sqrt(np.pi)*gamma(gam/2-0.5)/gamma(gam/2)\n",
    "ax.plot(R,wpR,'k-',label='IA484')\n",
    "ax.fill_between(R,wpdn,wpup,color='lightgrey')\n",
    "#\n",
    "ax.legend(title='$z={:.1f}$'.format(zz))\n",
    "ax.set_xlim(0.5, 50.0)\n",
    "ax.set_ylim(1.0,150.0)\n",
    "ax.set_xscale('log')\n",
    "ax.set_yscale('log')\n",
    "ax.set_xlabel(r'$R\\quad [h^{-1}\\,{\\rm Mpc}]$',fontsize=18)\n",
    "ax.set_ylabel(r'$w_p(R)\\quad [h^{-1}{\\rm Mpc}]$',fontsize=18)\n",
    "plt.tight_layout()\n",
    "plt.savefig('lae_IA484_wp.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d799bd9e-f7e3-4a63-a79a-d304862272e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,1,figsize=(6,4.5))\n",
    "# First plot the N-body xi_ell.\n",
    "ss   = np.array(lae['R'])\n",
    "s2   = ss**2\n",
    "icol = 1\n",
    "for samp in lae['mocks'][1:2]:\n",
    "    ax.plot(ss, s2*samp['xi0'],'s-',color='C'+str(icol),\\\n",
    "            mfc='None',label=\"{:5.2f}\".format(samp['hod'][0]))\n",
    "    ax.plot(ss,-s2*samp['xi2'],'o',color='C'+str(icol),mfc='None')\n",
    "    icol = (icol+1)%10\n",
    "ax.plot(xi0[0], xi0[0]**2*xi0[1],'k--',label=r'$\\ell = 0$')\n",
    "ax.plot(xi2[0],-xi2[0]**2*xi2[1],'k:' ,label=r'$\\ell = 2$')\n",
    "ax.legend(title='$z={:.1f}$'.format(zz))\n",
    "ax.set_xlim( 0,125.0)\n",
    "ax.set_ylim(-5, 40.0)\n",
    "ax.set_xscale('linear')\n",
    "ax.set_yscale('linear')\n",
    "ax.set_xlabel(r'$s\\quad [h^{-1}\\,{\\rm Mpc}]$',fontsize=18)\n",
    "ax.set_ylabel(r'$i^\\ell\\ s^2\\xi_\\ell(s)\\quad [h^{-2}{\\rm Mpc}^2]$',fontsize=18)\n",
    "plt.tight_layout()\n",
    "plt.savefig('lae_IA484_xi.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec00c87-dd25-4dfa-85e7-7f72dd99b4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can also look at the power spectra predicted by\n",
    "# this model.  We may want to adjust the stochastic terms.\n",
    "#\n",
    "# b1,b2,bs, b3: linear, quadratic & cubic bias parameters\n",
    "# alpha0,alpha2,alpha4,alpha6: counterterms\n",
    "# sn0,sn2, sn4: stochastic contributions to P(k) and sigma^2.\n",
    "stoch  = [0, 0, 0]\n",
    "pars   = biases + cterms + stoch\n",
    "#\n",
    "kl,p0,p2,p4 = lpt.combine_bias_terms_pkell(pars)\n",
    "#\n",
    "fig,ax = plt.subplots(1,1,figsize=(6,4.5))\n",
    "ax.plot(kl,kl*p0,'k--',label=r'$\\ell = 0$')\n",
    "ax.plot(kl,kl*p2,'k:' ,label=r'$\\ell = 2$')\n",
    "ax.legend(title='$z={:.1f}$'.format(zz))\n",
    "ax.set_xlim(0.0,0.5)\n",
    "ax.set_ylim(0.0,600)\n",
    "ax.set_xscale('linear')\n",
    "ax.set_yscale('linear')\n",
    "ax.set_xlabel(r'$k\\quad [h\\,{\\rm Mpc}^{-1}]$',fontsize=18)\n",
    "ax.set_ylabel(r'$k P_\\ell(k)\\quad [h^{-2}{\\rm Mpc}^2]$',fontsize=18)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bee6b57-a45a-4a9a-9cd0-a24e709b3b30",
   "metadata": {},
   "source": [
    "### Sample surveys\n",
    "\n",
    "Finally let's look at some sample surveys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9ec6ae-6ae4-41ea-8bfa-55785a51449a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lam = [4849.,5010.,6620.]\n",
    "dlam= [ 229.,75.00,160.0]\n",
    "#\n",
    "area= 100 * (np.pi/180.)**2  # Survey area in sr.\n",
    "#\n",
    "print(\"# Wavelengths in Angstroms, distances in (comoving) Mpc/h.\")\n",
    "print(\"# Assume survey area of 100 sq.deg.\")\n",
    "print(\"# {:>3s} {:>5s} {:>5s} {:>6s} {:>6s} {:>6s} {:>10s}\".\\\n",
    "      format(\"lam\",\"dlam\",\"zcen\",\"dz\",\"chi\",\"dchi\",\"dvol\"))\n",
    "for i in range(len(lam)):\n",
    "    zmid,dz= lam[i] / 1216. - 1.,dlam[i]/ 1216.\n",
    "    chi    = cosmo.comoving_distance(zmid) * cosmo.h()\n",
    "    dchi   = dz / cosmo.Hubble(zmid)       * cosmo.h()\n",
    "    dvol   = area * chi**2 * dchi\n",
    "    outstr = \"{:5.0f} {:5.0f}\".format(lam[i],dlam[i])\n",
    "    outstr+= \" {:5.2f} {:6.3f}\".format(zmid,dz)\n",
    "    outstr+= \" {:6.0f} {:6.0f}\".format(chi,dchi)\n",
    "    outstr+= \" {:10.1e}\".format(dvol)\n",
    "    print(outstr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e701f0-8326-4183-9881-05d5049c38d2",
   "metadata": {},
   "source": [
    "# Done"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CMB-env",
   "language": "python",
   "name": "cmb"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
